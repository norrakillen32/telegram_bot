import json
import re
from typing import Tuple, Optional, Dict, List, Any
import difflib

class TextPreprocessor:
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        text = text.lower().strip()
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text
    
    @staticmethod
    def extract_keywords(text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        stop_words = {
            '–∫–∞–∫', '–≥–¥–µ', '—á—Ç–æ', '–∫—Ç–æ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º',
            '–º–Ω–µ', '–º–Ω–æ–π', '–º–µ–Ω—è', '—Ç–µ–±–µ', '—Ç–æ–±–æ–π', '—Ç–µ–±—è',
            '—Å–≤–æ–π', '—Å–≤–æ—è', '—Å–≤–æ—ë', '—Å–≤–æ–∏',
            '—ç—Ç–æ', '—ç—Ç–æ—Ç', '—ç—Ç–∞', '—ç—Ç–∏', '—ç—Ç–æ—Ç',
            '–≤–æ—Ç', '—Ç—É—Ç', '—Ç–∞–º', '–∑–¥–µ—Å—å', '—Ç—É–¥–∞',
            '–æ—á–µ–Ω—å', '–ø—Ä–æ—Å—Ç–æ', '–≤–æ–æ–±—â–µ', '—Å–æ–≤—Å–µ–º',
            '–º–æ–∂–Ω–æ', '–Ω—É–∂–Ω–æ', '–Ω–∞–¥–æ', '—Ö–æ—á—É', '—Ö–æ—Ç–µ–ª'
        }
        
        words = text.split()
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        return keywords

class FuzzySearcher:
    """–ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    @staticmethod
    def fuzzy_ratio(text1: str, text2: str) -> float:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤"""
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text1 = text1.lower()
        text2 = text2.lower()
        
        # 1. –ë–∞–∑–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        base_ratio = difflib.SequenceMatcher(None, text1, text2).ratio()
        
        # 2. –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        words1 = text1.split()
        words2 = text2.split()
        
        # 3. –ù–∞—Ö–æ–¥–∏–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (–¥–∞–∂–µ —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)
        common_score = 0
        for w1 in words1:
            for w2 in words2:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if w1 in w2 or w2 in w1:
                    common_score += 1
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞ (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞)
                elif len(w1) > 3 and len(w2) > 3:
                    similarity = difflib.SequenceMatcher(None, w1, w2).ratio()
                    if similarity > 0.6:
                        common_score += similarity
        
        word_overlap = common_score / max(len(words1), len(words2), 1)
        
        # 4. –ü–µ—Ä–≤—ã–µ –±—É–∫–≤—ã —Å–ª–æ–≤
        first_letter_score = 0
        if words1 and words2:
            first_match = 0
            for i in range(min(len(words1), len(words2))):
                if words1[i][0] == words2[i][0]:
                    first_match += 1
            first_letter_score = first_match / max(len(words1), len(words2))
        
        # 5. –§–∏–Ω–∞–ª—å–Ω—ã–π score
        fuzzy_score = (base_ratio * 0.4) + (word_overlap * 0.4) + (first_letter_score * 0.2)
        return min(fuzzy_score, 1.0)

class KnowledgeBaseSearcher:
    """–ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    def __init__(self, file_path: str = "knowledge_base.json"):
        self.file_path = file_path
        self.kb_data = self._load_knowledge_base()
        self.preprocessor = TextPreprocessor()
        self.fuzzy_searcher = FuzzySearcher()
        self.question_index = self._build_index()
        # –°–æ–∑–¥–∞–¥–∏–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö —Å–ª–æ–≤
        self.synonym_index = self._build_synonym_index()
    
    def _build_synonym_index(self) -> Dict[str, List[str]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª–æ–≤"""
        synonyms = {
            '—Å–æ–∑–¥–∞–Ω–∏–µ': ['—Å–æ–∑–¥–∞—Ç—å', '—Å–æ–∑–¥–∞–π', '—Å–æ–∑–¥–∞–≤–∞—Ç—å', '—Å–æ–∑–¥–∞—é', '—Å–æ–∑–¥–∞–ª'],
            '–Ω–æ–≤–∞—è': ['–Ω–æ–≤—ã–π', '–Ω–æ–≤–æ–µ', '–Ω–æ–≤—ã–µ', '–Ω–æ–≤—É—é', '–Ω–æ–≤–æ–π'],
            '–Ω–∞–∫–ª–∞–¥–Ω–∞—è': ['–Ω–∞–∫–ª–∞–¥–Ω–æ–π', '–Ω–∞–∫–ª–∞–¥–Ω—ã–µ', '–Ω–∞–∫–ª–∞–¥–Ω—ã—Ö', '–Ω–∞–∫–ª–∞–¥–Ω—É—é', '–Ω–∞–∫–ª–∞–¥–Ω—ã–º'],
            '–æ—Ç—á–µ—Ç': ['–æ—Ç—á–µ—Ç–∞', '–æ—Ç—á–µ—Ç—ã', '–æ—Ç—á–µ—Ç–æ–≤', '–æ—Ç—á–µ—Ç–æ–º', '–æ—Ç—á–µ—Ç–∞–º'],
            '–ø–ª–∞—Ç–µ–∂': ['–ø–ª–∞—Ç–µ–∂–∞', '–ø–ª–∞—Ç–µ–∂–∏', '–ø–ª–∞—Ç–µ–∂–µ–π', '–ø–ª–∞—Ç–µ–∂–æ–º', '–ø–ª–∞—Ç–µ–∂–∞–º'],
            '–¥–æ–∫—É–º–µ–Ω—Ç': ['–¥–æ–∫—É–º–µ–Ω—Ç–∞', '–¥–æ–∫—É–º–µ–Ω—Ç—ã', '–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤', '–¥–æ–∫—É–º–µ–Ω—Ç–æ–º', '–¥–æ–∫—É–º–µ–Ω—Ç–∞–º'],
        }
        return synonyms
    
    def _expand_keywords(self, keywords: List[str]) -> List[str]:
        """–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏"""
        expanded = set(keywords)
        for keyword in keywords:
            if keyword in self.synonym_index:
                expanded.update(self.synonym_index[keyword])
        return list(expanded)
    
    def find_best_match(
        self, 
        user_question: str, 
        source_type: Optional[str] = None,
        threshold: float = 0.25  # –°–ù–ò–ñ–ï–ù–ù–´–ô –ü–û–†–û–ì
    ) -> Tuple[Optional[Dict], float]:
        if not self.kb_data:
            return None, 0.0
        
        normalized_question = self.preprocessor.normalize_text(user_question)
        keywords = self.preprocessor.extract_keywords(normalized_question)
        
        # –†–∞—Å—à–∏—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
        expanded_keywords = self._expand_keywords(keywords)
        
        best_item = None
        best_confidence = 0.0
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        candidate_items = []
        seen_ids = set()
        
        # –ò—â–µ–º –ø–æ –≤—Å–µ–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏ –∏—Ö —Å–∏–Ω–æ–Ω–∏–º–∞–º
        for keyword in expanded_keywords:
            if keyword in self.question_index:
                for item in self.question_index[keyword]:
                    item_id = item.get('id')
                    if item_id not in seen_ids:
                        seen_ids.add(item_id)
                        candidate_items.append(item)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º, –∏—â–µ–º –≤–æ –≤—Å–µ–π –±–∞–∑–µ
        if not candidate_items:
            candidate_items = self.kb_data
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        for item in candidate_items:
            item_question = item.get('question', '')
            item_source = item.get('source', 'manual')
            
            if source_type and item_source != source_type:
                continue
            
            normalized_item = self.preprocessor.normalize_text(item_question)
            
            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            similarity = self._calculate_similarity(normalized_question, normalized_item)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            partial_match_score = 0
            for kw in keywords:
                if kw in normalized_item:
                    partial_match_score += 0.2
            
            item_keywords = self.preprocessor.extract_keywords(normalized_item)
            common_keywords = set(keywords) & set(item_keywords)
            keyword_overlap = len(common_keywords) / max(len(keywords), 1)
            
            # –ù–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∞ —Å —É—á–µ—Ç–æ–º —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            confidence = (similarity * 0.4) + (keyword_overlap * 0.3) + (partial_match_score * 0.3)
            
            if confidence > best_confidence:
                best_confidence = confidence
                best_item = item
        
        print(f"üîç –ü–æ–∏—Å–∫: '{user_question}' -> –ª—É—á—à–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_confidence:.2f}")
        
        if best_confidence >= threshold:
            return best_item, best_confidence
        
        return None, 0.0
    
    def find_by_exact_question(
        self, 
        question: str, 
        source_type: Optional[str] = None
    ) -> Optional[Dict]:
        """–ü–æ–∏—Å–∫ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –≤–æ–ø—Ä–æ—Å—É"""
        normalized_question = self.preprocessor.normalize_text(question)
        
        for item in self.kb_data:
            item_question = self.preprocessor.normalize_text(item.get('question', ''))
            item_source = item.get('source', 'manual')
            
            if source_type and item_source != source_type:
                continue
            
            if item_question == normalized_question:
                return item
        
        return None

class IntentClassifier:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    
    def __init__(self):
        self.intents = {
            'greeting': ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä—ã–π', 'hello', 'hi', '–Ω–∞—á–∞—Ç—å', '–ø—Ä–∏–≤'],
            'farewell': ['–ø–æ–∫–∞', '–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è', '–≤—ã—Ö–æ–¥', '–∑–∞–∫–æ–Ω—á–∏—Ç—å', '—Å–ø–∞—Å–∏–±–æ', '–ø–æ–∫', '–≤—Å–µ–≥–æ'],
            'help': ['–ø–æ–º–æ—â—å', '–ø–æ–º–æ–≥–∏', '—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å', '–∫–æ–º–∞–Ω–¥—ã', '–ø–æ–¥—Å–∫–∞–∂–∏', '–ø–æ—Å–æ–≤–µ—Ç—É–π'],
            'question_1c': ['–∫–∞–∫', '–≥–¥–µ', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–º–æ–∂–Ω–æ –ª–∏', '–∫–∞–∫–æ–π', '—á–µ–º'],
            'document': ['–Ω–∞–∫–ª–∞–¥–Ω–∞—è', '—Å—á–µ—Ç', '–∞–∫—Ç', '–¥–æ–≥–æ–≤–æ—Ä', '–æ—Ä–¥–µ—Ä', '–æ—Ç—á–µ—Ç', '–¥–æ–∫—É–º–µ–Ω—Ç'],
            'operation': ['—Å–æ–∑–¥–∞—Ç—å', '—É–¥–∞–ª–∏—Ç—å', '–∏–∑–º–µ–Ω–∏—Ç—å', '–ø—Ä–æ–≤–µ—Å—Ç–∏', '–æ—Ç–º–µ–Ω–∏—Ç—å', '—Å–¥–µ–ª–∞—Ç—å', '–Ω–∞–ø–∏—Å–∞—Ç—å'],
            'search': ['–Ω–∞–π—Ç–∏', '–ø–æ–∏—Å–∫', '–∏—Å–∫–∞—Ç—å', '–≥–¥–µ –Ω–∞–π—Ç–∏', '–∫–∞–∫ –Ω–∞–π—Ç–∏', '–Ω–∞–π–¥–∏'],
            'button_click': ['button:', 'menu:', '–Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É', '–∫–ª–∏–∫ –ø–æ', '–∫–Ω–æ–ø–∫–∞']
        }
    
    def classify(self, text: str) -> List[str]:
        text_lower = text.lower()
        detected_intents = []
        for intent, keywords in self.intents.items():
            for keyword in keywords:
                if keyword in text_lower:
                    detected_intents.append(intent)
                    break
        return detected_intents if detected_intents else ['unknown']
    
    def is_button_click(self, text: str) -> Tuple[bool, Optional[str], Optional[str]]:
        text_lower = text.lower()
        
        for prefix in ['button:', 'menu:']:
            if text_lower.startswith(prefix):
                parts = text_lower.split(':', 1)
                if len(parts) == 2:
                    return True, prefix.rstrip(':'), parts[1].strip()
        
        button_patterns = [
            (['–Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É', '–Ω–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É', '–Ω–∞–∂—ã –∫–Ω–æ–ø–∫—É', '–Ω–∞–∂–∞—Ç—å–∫–Ω–æ–ø–∫—É'], 'button'),
            (['–∫–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ', '–∫–ª–∏–∫–Ω—É—Ç—å –∫–Ω–æ–ø–∫—É', '–∫–ª–∏–∫ –ø–æ', '–∫–ª–∏–∫–Ω—É—Ç—å'], 'button'),
            (['–≤ –º–µ–Ω—é', '–º–µ–Ω—é', '–≤ —Ä–∞–∑–µ–¥–µ–ª', '—Ä–∞–∑–µ–¥–µ–ª'], 'menu'),
            (['—Ä–∞–∑–¥–µ–ª', '—Ä–∞–∑–¥–∏–ª', '—Ä–∞–¥–µ–ª'], 'menu')
        ]
        
        for patterns, source_type in button_patterns:
            for pattern in patterns:
                if pattern in text_lower:
                    start_idx = text_lower.find(pattern) + len(pattern)
                    button_text = text_lower[start_idx:].strip()
                    if button_text:
                        return True, source_type, button_text
        
        return False, None, None

class ButtonHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏–π –∫–Ω–æ–ø–æ–∫ —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    def __init__(self, kb_searcher: KnowledgeBaseSearcher):
        self.kb_searcher = kb_searcher
        self.preprocessor = TextPreprocessor()
    
    def handle_button_click(
        self, 
        source_type: str, 
        button_text: str
    ) -> Optional[Dict]:
        normalized_button = self.preprocessor.normalize_text(button_text)
        
        exact_match = self.kb_searcher.find_by_exact_question(
            normalized_button, 
            source_type=source_type
        )
        
        if exact_match:
            return exact_match
        
        fuzzy_match, confidence = self.kb_searcher.find_best_match(
            normalized_button,
            source_type=source_type,
            threshold=0.3
        )
        
        if fuzzy_match and confidence >= 0.3:
            return fuzzy_match
        
        any_match, confidence = self.kb_searcher.find_best_match(
            normalized_button,
            threshold=0.35
        )
        
        if any_match:
            return any_match
        
        return None

class NLPEngine:
    """–û—Å–Ω–æ–≤–Ω–æ–π NLP-–¥–≤–∏–∂–æ–∫"""
    
    def __init__(self):
        self.preprocessor = TextPreprocessor()
        self.intent_classifier = IntentClassifier()
        self.kb_searcher = KnowledgeBaseSearcher()
        self.button_handler = ButtonHandler(self.kb_searcher)
        self._current_options = {}
        print("‚úÖ NLPEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.kb_searcher.kb_data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    
    def get_final_answer(self, user_message: str) -> str:
        print(f"üîç get_final_answer –≤—ã–∑–≤–∞–Ω —Å: '{user_message}'")
        try:
            analysis = self.process_message(user_message)
            
            if analysis['has_kb_answer']:
                kb_item = analysis['kb_item']
                answer = kb_item.get('answer', '')
                confidence = analysis['kb_confidence']
                
                # –°–ù–ò–ñ–ï–ù–ù–´–ô –ü–û–†–û–ì –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è
                if confidence < 0.4:  # –±—ã–ª–æ 0.65
                    print(f"üîÑ –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ({confidence:.2f}), –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏–µ")
                    clarification_response = self.get_clarification_response(analysis)
                    return clarification_response
                
                # –î–ª—è –∫–Ω–æ–ø–æ–∫ –¥–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ
                if analysis.get('is_button_click'):
                    source = kb_item.get('source', '')
                    button_text = kb_item.get('metadata', {}).get('button_text', '')
                    
                    if button_text and source in ['menu', 'button']:
                        header = f"üîò **{button_text}**\n\n"
                        return header + answer
                
                # –î–ª—è fuzzy match –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏–µ
                confidence_percent = int(confidence * 100)
                
                if analysis.get('is_fuzzy_match'):
                    original_question = kb_item.get('question', '')
                    return f"‚úÖ {answer}\n\n<i>(–í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É: '{original_question}'. –ù–∞–π–¥–µ–Ω–æ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {confidence_percent}%)</i>"
                else:
                    return f"‚úÖ {answer}\n\n<i>(–ù–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {confidence_percent}%)</i>"
            
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –≤–æ–ø—Ä–æ—Å—ã
            similar_questions = self._find_similar_questions(user_message)
            if similar_questions:
                return self._create_similar_questions_response(user_message, similar_questions)
            
            suggestions = self._get_search_suggestions(user_message)
            return f"ü§î <b>–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.</b>\n\n{suggestions}"
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_final_answer: {e}")
            import traceback
            traceback.print_exc()
            return f"‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞:</b>\n\n{str(e)[:200]}"
    
    def _find_similar_questions(self, user_message: str, limit: int = 5) -> List[Dict]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–∞–∂–µ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é"""
        similar = []
        normalized_query = self.preprocessor.normalize_text(user_message)
        
        for item in self.kb_searcher.kb_data:
            item_question = self.preprocessor.normalize_text(item.get('question', ''))
            similarity = self.kb_searcher._calculate_similarity(normalized_query, item_question)
            
            if similarity > 0.2:  # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
                similar.append({
                    'item': item,
                    'similarity': similarity,
                    'question': item.get('question', '')
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–∂–µ—Å—Ç–∏
        similar.sort(key=lambda x: x['similarity'], reverse=True)
        return similar[:limit]
    
    def _create_similar_questions_response(self, user_query: str, similar_questions: List[Dict]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ—Ö–æ–∂–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏"""
        if not similar_questions:
            return ""
        
        response = f"üîç <b>–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.</b>\n\n"
        response += f"<i>–í–æ–∑–º–æ–∂–Ω–æ, –≤–∞–º –ø–æ–¥–æ–π–¥–µ—Ç –æ–¥–∏–Ω –∏–∑ —ç—Ç–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:</i>\n\n"
        
        for i, sim in enumerate(similar_questions[:3], 1):
            question = sim['question']
            similarity = int(sim['similarity'] * 100)
            response += f"{i}. <b>{question}</b> (—Å—Ö–æ–¥—Å—Ç–≤–æ: {similarity}%)\n"
        
        response += f"\n<b>–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞ (1-{min(3, len(similar_questions))})</b>"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±–æ—Ä–∞
        self._current_options = {
            i: sim['item'] for i, sim in enumerate(similar_questions[:3], 1)
        }
        
        return response
    
    def get_option_selection(self, option_number: int) -> Optional[str]:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –æ–ø—Ü–∏–∏"""
        print(f"üîç –í—ã–±–æ—Ä –æ–ø—Ü–∏–∏ {option_number}, –¥–æ—Å—Ç—É–ø–Ω—ã–µ –æ–ø—Ü–∏–∏: {list(self._current_options.keys())}")
        
        if option_number in self._current_options:
            item = self._current_options[option_number]
            if isinstance(item, dict):
                answer = item.get('answer', '')
                source = item.get('source', '')
                
                if source in ['button', 'menu']:
                    button_text = item.get('metadata', {}).get('button_text', '')
                    return f"üîò **{button_text}**\n\n{answer}"
                else:
                    return answer
            else:
                print(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–ª–µ–º–µ–Ω—Ç–∞: {type(item)}")
                return None
        
        print(f"‚ö†Ô∏è –û–ø—Ü–∏—è {option_number} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return None
# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä NLP-–¥–≤–∏–∂–∫–∞
nlp_engine = NLPEngine()
