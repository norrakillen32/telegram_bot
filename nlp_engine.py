import json
import re
from typing import Tuple, Optional, Dict, List, Any
import difflib

class TextPreprocessor:
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        text = text.lower().strip()
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text
    
    @staticmethod
    def extract_keywords(text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        stop_words = {
            '–∫–∞–∫', '–≥–¥–µ', '—á—Ç–æ', '–∫—Ç–æ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º',
            '–º–Ω–µ', '–º–Ω–æ–π', '–º–µ–Ω—è', '—Ç–µ–±–µ', '—Ç–æ–±–æ–π', '—Ç–µ–±—è',
            '—Å–≤–æ–π', '—Å–≤–æ—è', '—Å–≤–æ—ë', '—Å–≤–æ–∏',
            '—ç—Ç–æ', '—ç—Ç–æ—Ç', '—ç—Ç–∞', '—ç—Ç–∏', '—ç—Ç–æ—Ç',
            '–≤–æ—Ç', '—Ç—É—Ç', '—Ç–∞–º', '–∑–¥–µ—Å—å', '—Ç—É–¥–∞',
            '–æ—á–µ–Ω—å', '–ø—Ä–æ—Å—Ç–æ', '–≤–æ–æ–±—â–µ', '—Å–æ–≤—Å–µ–º',
            '–º–æ–∂–Ω–æ', '–Ω—É–∂–Ω–æ', '–Ω–∞–¥–æ', '—Ö–æ—á—É', '—Ö–æ—Ç–µ–ª'
        }
        
        words = text.split()
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        return keywords

class FuzzySearcher:
    """–ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    @staticmethod
    def fuzzy_ratio(text1: str, text2: str) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
        base_ratio = difflib.SequenceMatcher(None, text1, text2).ratio()
        words1 = text1.split()
        words2 = text2.split()
        word_overlap = len(set(words1) & set(words2)) / max(len(set(words1)), 1)
        first_letter_score = 0
        if words1 and words2:
            if words1[0][0] == words2[0][0]:
                first_letter_score = 0.2
        fuzzy_score = (base_ratio * 0.6) + (word_overlap * 0.3) + (first_letter_score * 0.1)
        return fuzzy_score

class KnowledgeBaseSearcher:
    """–ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    def __init__(self, file_path: str = "knowledge_base.json"):
        self.file_path = file_path
        self.kb_data = self._load_knowledge_base()
        self.preprocessor = TextPreprocessor()
        self.fuzzy_searcher = FuzzySearcher()
        self.question_index = self._build_index()
    
    def _load_knowledge_base(self) -> List[Dict]:
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(data)} –∑–∞–ø–∏—Å–µ–π")
                return data
        except FileNotFoundError:
            print(f"‚ö†Ô∏è –§–∞–π–ª {self.file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {e}")
            return []
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
            return []
    
    def _build_index(self) -> Dict[str, List[Dict]]:
        index = {}
        for item in self.kb_data:
            question = item.get('question', '')
            normalized = self.preprocessor.normalize_text(question)
            keywords = self.preprocessor.extract_keywords(normalized)
            for keyword in keywords:
                if keyword not in index:
                    index[keyword] = []
                index[keyword].append(item)
        return index
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        return self.fuzzy_searcher.fuzzy_ratio(text1, text2)
    
    def find_best_match(
        self, 
        user_question: str, 
        source_type: Optional[str] = None,
        threshold: float = 0.4
    ) -> Tuple[Optional[Dict], float]:
        if not self.kb_data:
            return None, 0.0
        
        normalized_question = self.preprocessor.normalize_text(user_question)
        keywords = self.preprocessor.extract_keywords(normalized_question)
        
        best_item = None
        best_confidence = 0.0
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è ID —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        seen_ids = set()
        candidate_items = []
        
        for keyword in keywords:
            if keyword in self.question_index:
                for item in self.question_index[keyword]:
                    item_id = item.get('id')
                    if item_id is None:
                        # –ï—Å–ª–∏ —É —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–µ—Ç ID, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –∫–∞–∫ –∫–ª—é—á
                        item_key = item.get('question', '')
                    else:
                        item_key = item_id
                    
                    if item_key not in seen_ids:
                        seen_ids.add(item_key)
                        candidate_items.append(item)
        
        if not candidate_items:
            candidate_items = self.kb_data
        
        for item in candidate_items:
            item_question = item.get('question', '')
            item_source = item.get('source', 'manual')
            
            if source_type and item_source != source_type:
                continue
            
            normalized_item = self.preprocessor.normalize_text(item_question)
            similarity = self._calculate_similarity(normalized_question, normalized_item)
            
            item_keywords = self.preprocessor.extract_keywords(normalized_item)
            common_keywords = set(keywords) & set(item_keywords)
            keyword_overlap = len(common_keywords) / max(len(keywords), 1)
            
            confidence = (similarity * 0.6) + (keyword_overlap * 0.4)
            
            if confidence > best_confidence:
                best_confidence = confidence
                best_item = item
        
        if best_confidence >= threshold:
            return best_item, best_confidence
        
        return None, 0.0
    
    def find_by_exact_question(
        self, 
        question: str, 
        source_type: Optional[str] = None
    ) -> Optional[Dict]:
        """–ü–æ–∏—Å–∫ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –≤–æ–ø—Ä–æ—Å—É"""
        normalized_question = self.preprocessor.normalize_text(question)
        
        for item in self.kb_data:
            item_question = self.preprocessor.normalize_text(item.get('question', ''))
            item_source = item.get('source', 'manual')
            
            if source_type and item_source != source_type:
                continue
            
            if item_question == normalized_question:
                return item
        
        return None

class IntentClassifier:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    
    def __init__(self):
        self.intents = {
            'greeting': ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä—ã–π', 'hello', 'hi', '–Ω–∞—á–∞—Ç—å', '–ø—Ä–∏–≤'],
            'farewell': ['–ø–æ–∫–∞', '–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è', '–≤—ã—Ö–æ–¥', '–∑–∞–∫–æ–Ω—á–∏—Ç—å', '—Å–ø–∞—Å–∏–±–æ', '–ø–æ–∫', '–≤—Å–µ–≥–æ'],
            'help': ['–ø–æ–º–æ—â—å', '–ø–æ–º–æ–≥–∏', '—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å', '–∫–æ–º–∞–Ω–¥—ã', '–ø–æ–¥—Å–∫–∞–∂–∏', '–ø–æ—Å–æ–≤–µ—Ç—É–π'],
            'question_1c': ['–∫–∞–∫', '–≥–¥–µ', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–º–æ–∂–Ω–æ –ª–∏', '–∫–∞–∫–æ–π', '—á–µ–º'],
            'document': ['–Ω–∞–∫–ª–∞–¥–Ω–∞—è', '—Å—á–µ—Ç', '–∞–∫—Ç', '–¥–æ–≥–æ–≤–æ—Ä', '–æ—Ä–¥–µ—Ä', '–æ—Ç—á–µ—Ç', '–¥–æ–∫—É–º–µ–Ω—Ç'],
            'operation': ['—Å–æ–∑–¥–∞—Ç—å', '—É–¥–∞–ª–∏—Ç—å', '–∏–∑–º–µ–Ω–∏—Ç—å', '–ø—Ä–æ–≤–µ—Å—Ç–∏', '–æ—Ç–º–µ–Ω–∏—Ç—å', '—Å–¥–µ–ª–∞—Ç—å', '–Ω–∞–ø–∏—Å–∞—Ç—å'],
            'search': ['–Ω–∞–π—Ç–∏', '–ø–æ–∏—Å–∫', '–∏—Å–∫–∞—Ç—å', '–≥–¥–µ –Ω–∞–π—Ç–∏', '–∫–∞–∫ –Ω–∞–π—Ç–∏', '–Ω–∞–π–¥–∏'],
            'button_click': ['button:', 'menu:', '–Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É', '–∫–ª–∏–∫ –ø–æ', '–∫–Ω–æ–ø–∫–∞']
        }
    
    def classify(self, text: str) -> List[str]:
        text_lower = text.lower()
        detected_intents = []
        for intent, keywords in self.intents.items():
            for keyword in keywords:
                if keyword in text_lower:
                    detected_intents.append(intent)
                    break
        return detected_intents if detected_intents else ['unknown']
    
    def is_button_click(self, text: str) -> Tuple[bool, Optional[str], Optional[str]]:
        text_lower = text.lower()
        
        for prefix in ['button:', 'menu:']:
            if text_lower.startswith(prefix):
                parts = text_lower.split(':', 1)
                if len(parts) == 2:
                    return True, prefix.rstrip(':'), parts[1].strip()
        
        button_patterns = [
            (['–Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É', '–Ω–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É', '–Ω–∞–∂—ã –∫–Ω–æ–ø–∫—É', '–Ω–∞–∂–∞—Ç—å–∫–Ω–æ–ø–∫—É'], 'button'),
            (['–∫–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ', '–∫–ª–∏–∫–Ω—É—Ç—å –∫–Ω–æ–ø–∫—É', '–∫–ª–∏–∫ –ø–æ', '–∫–ª–∏–∫–Ω—É—Ç—å'], 'button'),
            (['–≤ –º–µ–Ω—é', '–º–µ–Ω—é', '–≤ —Ä–∞–∑–µ–¥–µ–ª', '—Ä–∞–∑–µ–¥–µ–ª'], 'menu'),
            (['—Ä–∞–∑–¥–µ–ª', '—Ä–∞–∑–¥–∏–ª', '—Ä–∞–¥–µ–ª'], 'menu')
        ]
        
        for patterns, source_type in button_patterns:
            for pattern in patterns:
                if pattern in text_lower:
                    start_idx = text_lower.find(pattern) + len(pattern)
                    button_text = text_lower[start_idx:].strip()
                    if button_text:
                        return True, source_type, button_text
        
        return False, None, None

class ButtonHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏–π –∫–Ω–æ–ø–æ–∫ —Å —É—á–µ—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
    
    def __init__(self, kb_searcher: KnowledgeBaseSearcher):
        self.kb_searcher = kb_searcher
        self.preprocessor = TextPreprocessor()
    
    def handle_button_click(
        self, 
        source_type: str, 
        button_text: str
    ) -> Optional[Dict]:
        normalized_button = self.preprocessor.normalize_text(button_text)
        
        exact_match = self.kb_searcher.find_by_exact_question(
            normalized_button, 
            source_type=source_type
        )
        
        if exact_match:
            return exact_match
        
        fuzzy_match, confidence = self.kb_searcher.find_best_match(
            normalized_button,
            source_type=source_type,
            threshold=0.3
        )
        
        if fuzzy_match and confidence >= 0.3:
            return fuzzy_match
        
        any_match, confidence = self.kb_searcher.find_best_match(
            normalized_button,
            threshold=0.35
        )
        
        if any_match:
            return any_match
        
        return None

class NLPEngine:
    """–û—Å–Ω–æ–≤–Ω–æ–π NLP-–¥–≤–∏–∂–æ–∫"""
    
    def __init__(self):
        self.preprocessor = TextPreprocessor()
        self.intent_classifier = IntentClassifier()
        self.kb_searcher = KnowledgeBaseSearcher()
        self.button_handler = ButtonHandler(self.kb_searcher)
        self._current_options = {}
        print("‚úÖ NLPEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.kb_searcher.kb_data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    
    def process_message(self, user_message: str) -> Dict[str, Any]:
        print(f"\nüì® –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: '{user_message}'")
        
        is_button_click, source_type, button_text = self.intent_classifier.is_button_click(user_message)
        
        if is_button_click and source_type and button_text:
            print(f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∫–∞–∫ –Ω–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏: {source_type} -> '{button_text}'")
            
            kb_item = self.button_handler.handle_button_click(source_type, button_text)
            
            if kb_item:
                return {
                    'original_message': user_message,
                    'normalized_message': button_text,
                    'intents': ['button_click'],
                    'source_type': source_type,
                    'kb_answer': kb_item.get('answer'),
                    'kb_item': kb_item,
                    'kb_confidence': 1.0,
                    'has_kb_answer': True,
                    'is_button_click': True,
                    'is_fuzzy_match': False
                }
        
        normalized = self.preprocessor.normalize_text(user_message)
        intents = self.intent_classifier.classify(normalized)
        keywords = self.preprocessor.extract_keywords(normalized)
        
        kb_item, kb_confidence = self.kb_searcher.find_best_match(
            user_message, 
            threshold=0.35
        )
        
        is_fuzzy_match = False
        if kb_item and kb_confidence < 0.7:
            original_question = kb_item.get('question', '')
            if original_question.lower() != normalized:
                is_fuzzy_match = True
        
        result = {
            'original_message': user_message,
            'normalized_message': normalized,
            'intents': intents,
            'keywords': keywords,
            'kb_answer': kb_item.get('answer') if kb_item else None,
            'kb_item': kb_item,
            'kb_confidence': kb_confidence,
            'has_kb_answer': kb_item is not None,
            'is_button_click': False,
            'is_fuzzy_match': is_fuzzy_match
        }
        
        return result
    
    def get_final_answer(self, user_message: str) -> str:
        print(f"üîç get_final_answer –≤—ã–∑–≤–∞–Ω —Å: '{user_message}'")
        try:
            analysis = self.process_message(user_message)
            
            if analysis['has_kb_answer']:
                kb_item = analysis['kb_item']
                answer = kb_item.get('answer', '')
                confidence = analysis['kb_confidence']
                
                # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è (< 65%), –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —É—Ç–æ—á–Ω–∏—Ç—å
                if confidence < 0.65:
                    clarification_response = self.get_clarification_response(analysis)
                    return clarification_response
                
                # –î–ª—è –∫–Ω–æ–ø–æ–∫ –¥–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ
                if analysis.get('is_button_click'):
                    source = kb_item.get('source', '')
                    button_text = kb_item.get('metadata', {}).get('button_text', '')
                    
                    if button_text and source in ['menu', 'button']:
                        header = f"üîò **{button_text}**\n\n"
                        return header + answer
                
                # –î–ª—è fuzzy match –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏–µ
                confidence_percent = int(confidence * 100)
                
                if analysis.get('is_fuzzy_match'):
                    original_question = kb_item.get('question', '')
                    return f"‚úÖ {answer}\n\n<i>(–í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É: '{original_question}'. –ù–∞–π–¥–µ–Ω–æ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {confidence_percent}%)</i>"
                else:
                    return f"‚úÖ {answer}\n\n<i>(–ù–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {confidence_percent}%)</i>"
            
            suggestions = self._get_search_suggestions(user_message)
            return f"ü§î <b>–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.</b>\n\n{suggestions}"
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_final_answer: {e}")
            import traceback
            traceback.print_exc()
            return f"‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞:</b>\n\n{str(e)[:200]}"
    
    def get_clarification_response(self, analysis: Dict) -> str:
        kb_item = analysis.get('kb_item')
        if not kb_item:
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."
        
        original_q = kb_item.get('question', '')
        item_tags = kb_item.get('tags', [])
        item_id = kb_item.get('id')
        
        # –ò—â–µ–º –≤–æ–ø—Ä–æ—Å—ã –≤ —Ç–µ—Ö –∂–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
        category_questions = self._get_questions_by_categories(
            item_tags, 
            exclude_id=item_id,
            min_relevance=0.2
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        return self._create_interactive_clarification(
            original_q,
            category_questions,
            "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
            user_query=analysis.get('original_message', '')
        )
    
    def _get_questions_by_categories(
        self, 
        categories: List[str], 
        exclude_id: Optional[int] = None,
        limit: int = 4,
        min_relevance: float = 0.1
    ) -> List[Dict]:
        if not categories:
            return []
        
        categorized_items = []
        
        for item in self.kb_searcher.kb_data:
            if exclude_id and item.get('id') == exclude_id:
                continue
                
            item_tags = item.get('tags', [])
            common_tags = set(categories) & set(item_tags)
            
            if common_tags:
                relevance_score = len(common_tags) / len(categories)
                
                if relevance_score >= min_relevance:
                    categorized_items.append({
                        'item': item,
                        'relevance': relevance_score,
                        'question': item.get('question', ''),
                        'tags': item_tags
                    })
        
        categorized_items.sort(key=lambda x: x['relevance'], reverse=True)
        return categorized_items[:limit]
    
    def _create_interactive_clarification(
        self, 
        original_question: str,
        alternative_questions: List[Dict],
        intent_description: str,
        user_query: str = ""
    ) -> str:
        if not alternative_questions:
            return (
                "ü§î **–ú–Ω–µ –Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–µ–Ω–∏–µ.**\n\n"
                f"–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É **¬´{user_query[:50]}...¬ª** —è –Ω–∞—à–µ–ª:\n"
                f"**¬´{original_question}¬ª**\n\n"
                "*–ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç–æ, —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ:*\n"
                "‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞\n"
                "‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Ä–∞–∑–¥–µ–ª–∞–º –º–µ–Ω—é\n"
                "‚Ä¢ –°—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ"
            )
        
        alternatives_text = []
        option_counter = 1
        option_map = {}
        
        for alt in alternative_questions[:3]:
            question = alt['question']
            tags_preview = ", ".join(alt.get('tags', [])[:2]) if alt.get('tags') else ""
            
            option_map[option_counter] = alt
            if tags_preview:
                alternatives_text.append(f"{option_counter}. üîπ **{question}** *({tags_preview})*")
            else:
                alternatives_text.append(f"{option_counter}. üîπ **{question}**")
            option_counter += 1
        
        self._current_options = option_map
        
        message = (
            f"üîç **–ù—É–∂–Ω–æ —É—Ç–æ—á–Ω–µ–Ω–∏–µ**\n\n"
            f"–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É —è –Ω–∞—à–µ–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:\n\n"
            f"{chr(10).join(alternatives_text)}\n\n"
            f"**–ö–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –≤–∞–º –Ω—É–∂–µ–Ω?**\n"
            f"‚Ä¢ –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–æ–º–µ—Ä–æ–º (1-{option_counter-1}) –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–±–æ—Ä–∞\n"
            f"‚Ä¢ –ò–ª–∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –∑–∞–ø—Ä–æ—Å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ\n"
            f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞\n\n"
            f"*–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å: ¬´{user_query}¬ª*"
        )
        
        return message
    
    def _get_search_suggestions(self, query: str) -> str:
        normalized = self.preprocessor.normalize_text(query)
        keywords = self.preprocessor.extract_keywords(normalized)
        
        similar_questions = []
        
        for item in self.kb_searcher.kb_data[:10]:
            item_question = self.preprocessor.normalize_text(item.get('question', ''))
            item_keywords = self.preprocessor.extract_keywords(item_question)
            common = set(keywords) & set(item_keywords)
            
            if len(common) >= 1 and item_question not in similar_questions:
                similar_questions.append(item_question)
            
            if len(similar_questions) >= 3:
                break
        
        suggestions = "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
        suggestions += "1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é\n"
        suggestions += "2. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å\n"
        
        if similar_questions:
            suggestions += "3. –í–æ–∑–º–æ–∂–Ω–æ, –≤–∞–º –Ω—É–∂–µ–Ω –æ–¥–∏–Ω –∏–∑ —ç—Ç–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤:\n"
            for i, q in enumerate(similar_questions, 1):
                suggestions += f"   ‚Ä¢ {q}\n"
        
        suggestions += "4. –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É"
        
        return suggestions
    
    def get_option_selection(self, option_number: int) -> Optional[str]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –æ–ø—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"""
        if option_number in self._current_options:
            selected = self._current_options[option_number]
            item = selected['item']
            answer = item.get('answer', '')
            source = item.get('source', '')
            
            if source in ['button', 'menu']:
                button_text = item.get('metadata', {}).get('button_text', '')
                return f"üîò **{button_text}**\n\n{answer}"
            else:
                return answer
        
        return None   
# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä NLP-–¥–≤–∏–∂–∫–∞
nlp_engine = NLPEngine()
